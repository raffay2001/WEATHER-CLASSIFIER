{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../../../data/cleaned_weather_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = dataset.iloc[0:, 0:11].values\n",
    "output = dataset['Summary'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(input, output, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 0.001, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Accuracy: 0.45709828393135726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\Envs\\ml-cep\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "24 fits failed out of a total of 96.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Administrator\\Envs\\ml-cep\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Administrator\\Envs\\ml-cep\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1207, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "  File \"c:\\Users\\Administrator\\Envs\\ml-cep\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 90, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Administrator\\Envs\\ml-cep\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.44792276 0.44792276 0.44148651 0.44411961        nan 0.44792276\n",
      "        nan 0.44275433 0.44363202 0.44372956 0.44002335 0.44090096\n",
      "        nan 0.44333966        nan 0.44021824 0.43904804 0.43904804\n",
      " 0.43904804 0.43904804        nan 0.43973061        nan 0.43973061]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters you want to search over\n",
    "parameters = {'solver': ['liblinear', 'saga'], \n",
    "              'multi_class':['ovr', 'multinomial'],\n",
    "              'C':[0.001, 0.01, 10.0],\n",
    "              'penalty': ['l1', 'l2']}\n",
    "\n",
    "# Create a logistic regression model\n",
    "logistic_regression = LogisticRegression(n_jobs=1)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=logistic_regression, param_grid=parameters, cv=4)\n",
    "\n",
    "# Fit the grid search on the training data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best hyperparameter values and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-cep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
